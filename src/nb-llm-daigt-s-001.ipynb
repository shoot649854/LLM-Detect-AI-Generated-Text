{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shotomorisaki/Engineering/LLM-Detect-AI-Generated-Text/src/nb-s-002.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "## Importing Libraries\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\n",
    "from sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "reg_dict = {\"LinearRegression\": LinearRegression(),\n",
    "            \"Ridge\": Ridge(),\n",
    "            \"Lasso\": Lasso(),\n",
    "            \"ElasticNet\": ElasticNet(), \n",
    "            \"Polynomial_deg2\": Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg3\": Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg4\": Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg5\": Pipeline([('poly', PolynomialFeatures(degree=5)),('linear', LinearRegression())]),\n",
    "            \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=3),\n",
    "            \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "            \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "            \"SVR\": SVR(kernel='rbf', C=1e3, gamma=0.1, epsilon=0.1),\n",
    "            \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "            \"SGDRegressor\": SGDRegressor(),\n",
    "            \"MLPRegressor\": MLPRegressor(hidden_layer_sizes=(10,10), max_iter=100, early_stopping=True, n_iter_no_change=5),\n",
    "            \"ExtraTreesRegressor\": ExtraTreesRegressor(n_estimators=100), \n",
    "            \"PLSRegression\": PLSRegression(n_components=10),\n",
    "            \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(max_iter=100, tol=1e-3),\n",
    "            \"TheilSenRegressor\": TheilSenRegressor(random_state=0),\n",
    "            \"RANSACRegressor\": RANSACRegressor(random_state=0),\n",
    "            \"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(),\n",
    "            \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n",
    "            \"BaggingRegressor\": BaggingRegressor(base_estimator=SVR(), n_estimators=10),\n",
    "            \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "            \"VotingRegressor\": VotingRegressor([('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=10))]),\n",
    "            \"StackingRegressor\": StackingRegressor(estimators=[('lr', RidgeCV()), ('svr', LinearSVR())], final_estimator=RandomForestRegressor(n_estimators=10)),\n",
    "            \"ARDRegression\": ARDRegression(),\n",
    "            \"HuberRegressor\": HuberRegressor(),\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv('../data/train_essays')\n",
    "st.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Cheking data types, checking data loss, any nun? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Gender', 'Item Purchased', 'Category', 'Purchase Amount (USD)', 'Location', 'Size', 'Color', 'Season', 'Review Rating',\n",
    "                        'Subscription Status', 'Shipping Type', 'Discount Applied', 'Promo Code Used', \n",
    "                        'Payment Method', 'Frequency of Purchases']\n",
    "\n",
    "df = st[columns]\n",
    "df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#データ内に欠損値があるかどうかを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df.copy()#コピーを作成する\n",
    "train_x = train_x.drop([], axis=1)# 指定した行を削除\n",
    "display(train_x)#データを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = df['Purchase Amount (USD)']\n",
    "y_axis = df['Review Rating']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_axis, y_axis, alpha=0.5)\n",
    "plt.title('Item Purchased vs Review Rating')\n",
    "plt.xlabel('Item Purchased')\n",
    "plt.ylabel('Review Rating')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "non_numeric_columns = ['Gender', 'Item Purchased', 'Category', 'Location', 'Size', 'Color', 'Season',\n",
    "                        'Subscription Status', 'Shipping Type', 'Discount Applied', 'Promo Code Used', \n",
    "                        'Payment Method', 'Frequency of Purchases']\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df[col])\n",
    "    df[col] = encoder.transform(df[col])\n",
    "    train_x[col] = encoder.transform(train_x[col])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
